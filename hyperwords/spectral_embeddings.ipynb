{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from scipy.sparse.linalg import lobpcg, eigsh\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the word2id index..\n",
      "Reading the count data...\n",
      "Building the adjacency matrix...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Build adjacency matrix from counts\n",
    "print(\"Building the word2id index..\")\n",
    "vocab_path = \"/Users/i.lobov/hyperwords/data/wiki/wikipedia.corpus.nodups_counts_win=1.words.vocab\"\n",
    "word2id = {}\n",
    "with open(vocab_path, 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        split_line = line.strip().split(\",\")\n",
    "        word = \",\".join(split_line[:len(split_line)-1])\n",
    "        word2id[word] = idx\n",
    "\n",
    "print(\"Reading the count data...\")\n",
    "N = len(word2id)\n",
    "counts_path = \"/Users/i.lobov/hyperwords/data/wiki/wikipedia.corpus.nodups_counts_win=1\"\n",
    "data = []\n",
    "rows = []\n",
    "cols = []\n",
    "\n",
    "with open(counts_path, 'r') as f:\n",
    "    for line in f:\n",
    "        count, word_a, word_b = line.strip().split()\n",
    "        word_a_id = word2id[word_a]\n",
    "        word_b_id = word2id[word_b]\n",
    "        \n",
    "        data.append(float(count))\n",
    "        rows.append(word_a_id)\n",
    "        cols.append(word_b_id)\n",
    "\n",
    "print(\"Building the adjacency matrix...\")\n",
    "adjacency_matrix = csr_matrix((data, (rows, cols)), shape=[N,N])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_path = \"/Users/i.lobov/hyperwords/data/wiki/wikipedia.corpus.nodups_counts_win=1.adj\"\n",
    "#scipy.sparse.save_npz(adj_path, adjacency_matrix)\n",
    "adjacency_matrix = scipy.sparse.load_npz(adj_path + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find spectral embeddings\n",
    "d=300\n",
    "#max_iter=1000\n",
    "#verbosity=1\n",
    "#seed=0\n",
    "\n",
    "degrees = adjacency_matrix.sum(axis=1).flatten()\n",
    "n = adjacency_matrix.shape[0]\n",
    "D = scipy.sparse.spdiags(degrees, [0], n, n, format='csr')\n",
    "L = D - adjacency_matrix\n",
    "degrees_sqrt = 1.0 / scipy.sqrt(degrees)\n",
    "DH = scipy.sparse.spdiags(degrees_sqrt, [0], n, n, format='csr')\n",
    "L_norm = DH.dot(L.dot(DH))\n",
    "\n",
    "#rng = np.random.RandomState(seed)\n",
    "#init = rng.rand(n, d + 1)\n",
    "#init[:,0] = 1.0/adjacency_matrix.sum(axis=1).flatten()\n",
    "#vals, vecs = lobpcg(A=L_norm, X=init, largest=False, maxiter=max_iter, verbosityLevel=verbosity)\n",
    "vals, vecs = eigsh(L_norm, k=d+1, which=\"SM\")\n",
    "\n",
    "# eigen_scaling = 1.0 / (vals[1:])\n",
    "# rescaled_eigenvectors = np.sqrt(eigen_scaling) * vecs[:, 1:] / np.sqrt(np.asarray(degrees).T)\n",
    "# rescaled_eigenvectors = np.ascontiguousarray(rescaled_eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"/Users/i.lobov/hyperwords/data/wiki/spectral_embeddings_d=300.words\"\n",
    "# np.save(save_path, rescaled_eigenvectors)\n",
    "\n",
    "# save_path = \"/Users/i.lobov/hyperwords/data/wiki/eigenvectors_d=500.words\"\n",
    "# np.save(save_path, vecs)\n",
    "\n",
    "# save_path = \"/Users/i.lobov/hyperwords/data/wiki/eigenvalues_d=500.words\"\n",
    "# np.save(save_path, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"/Users/i.lobov/hyperwords/data/wiki/eigenvectors_d=300.words.npy\"\n",
    "# vecs = np.load(save_path)\n",
    "\n",
    "# save_path = \"/Users/i.lobov/hyperwords/data/wiki/eigenvalues_d=300.words.npy\"\n",
    "# vals = np.load(save_path)\n",
    "\n",
    "# degrees = adjacency_matrix.sum(axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_scaling = 1.0 / (vals[1:])\n",
    "rescaled_eigenvectors = np.sqrt(eigen_scaling) * vecs[:, 1:] / np.sqrt(np.asarray(degrees).T)\n",
    "rescaled_eigenvectors = np.ascontiguousarray(rescaled_eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/i.lobov/hyperwords/testsets/ws/ws353.txt\"\n",
    "test = []\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        x, y, sim = line.strip().lower().split()\n",
    "        test.append(((x, y), float(sim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from representations.matrix_serializer import load_vocabulary\n",
    "\n",
    "path = \"/Users/i.lobov/hyperwords/data/wiki/wikipedia.corpus.nodups_counts_win=1.words.vocab\"\n",
    "wi, iw = load_vocabulary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21888865179835149"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "m = np.sqrt(eigenvals[1:]) * vecs[:,1:].copy()\n",
    "m = m / np.linalg.norm(m, axis=1, keepdims=True)\n",
    "dim = 300\n",
    "C = degrees.sum() / 10.0\n",
    "\n",
    "def represent(w):\n",
    "    if w in wi:\n",
    "        return m[wi[w], :]\n",
    "    else:\n",
    "        return np.zeros(dim)\n",
    "\n",
    "# def similarity(w1, w2):\n",
    "#     rep_w1 = represent(w1)\n",
    "#     rep_w2 = represent(w2)\n",
    "#     inner_product = np.log(max(C * rep_w1.dot(rep_w2), 1.0))\n",
    "#     w1_l2 = np.log(C * rep_w1.dot(rep_w1))\n",
    "#     w2_l2 = np.log(C * rep_w2.dot(rep_w2))\n",
    "#     #print(inner_product, rep_w1.dot(rep_w2))\n",
    "    \n",
    "#     return inner_product/np.sqrt(w1_l2*w2_l2)\n",
    "\n",
    "\n",
    "def similarity(w1, w2):\n",
    "    return represent(w1).dot(represent(w2))\n",
    "\n",
    "results = []\n",
    "for (x, y), sim in test:\n",
    "    results.append((similarity(x, y), sim))\n",
    "actual, expected = zip(*results)\n",
    "spearmanr(actual, expected)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "\n",
    "eigenvals = np.zeros_like(vals)\n",
    "for r in range(1, window+1):\n",
    "    eigenvals += vals**r\n",
    "eigenvals /= window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actuals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e9a8dd5b190e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'actuals' is not defined"
     ]
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.815510557964274"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
